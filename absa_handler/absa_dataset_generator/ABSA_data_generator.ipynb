{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "id": "7ScHfR4vKDnL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f33661d5-924e-4cde-fcd4-cc76f713b937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.42.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Downloading openai-1.42.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.9/362.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jiter-0.5.0 openai-1.42.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhwT8pb0VIQC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "656ed905-0000-463a-af32-413508a7eacd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Imported data\n"
          ]
        }
      ],
      "source": [
        "import gzip\n",
        "import json\n",
        "import os\n",
        "import shutil\n",
        "import csv\n",
        "import requests\n",
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "import random\n",
        "from random import randrange\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "client = OpenAI(api_key = \"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\")\n",
        "\n",
        "\n",
        "def pair_review_with_talking_points_and_sentiments(review_text, talking_points_and_sentiments):\n",
        "    # Split the input text at the \"<>\" separator\n",
        "    talking_points_str, sentiments_str = talking_points_and_sentiments.split('<>')\n",
        "\n",
        "    # Strip any trailing semicolons and then split the strings by semicolons\n",
        "    talking_points = talking_points_str.strip(';').strip().split(';')\n",
        "    sentiments = sentiments_str.strip(';').strip().split(';')\n",
        "\n",
        "    # Pair the review text with each talking point and corresponding sentiment\n",
        "    paired_list = [f\"{review_text},{tp.strip()},{sent.strip()}\" for tp, sent in zip(talking_points, sentiments) if tp.strip() and sent.strip()]\n",
        "\n",
        "    return paired_list\n",
        "\n",
        "\n",
        "def list_to_csv(data_list, output_filename):\n",
        "    # Open the file in write mode\n",
        "    with open(output_filename, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "\n",
        "        # Write each element of the list as a row in the CSV file\n",
        "        for line in data_list:\n",
        "            # Split the line by semicolons to get individual columns\n",
        "            row = line.split(';')\n",
        "            writer.writerow(row)\n",
        "\n",
        "\n",
        "def ask_gpt(prompt: str, model='gpt-3.5-turbo-1106'):\n",
        "    completion = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are now answering questions on products and product reviews on Amazon. \"\n",
        "                                          \"You will be treated like an API. Hence, you will only respond in a format, \"\n",
        "                                          \"that can be parsed by a computer. \"\n",
        "                                          \"Your answer will only contain spans of text that are also present in the\"\n",
        "                                          \"review you have been handed. You extract talking points and their contextual sentiment from product review texts.\"\n",
        "                                          \"Talking points are things that the reviewer mentions in his/her review about the product that affect\"\n",
        "                                          \"his/her decision to rate the product with a higher or lower score. You extract only the words and phrases\"\n",
        "                                          \"that are in the text itself, you should not add anything yourself.\"\n",
        "\n",
        "                                          \"Example review text: \\\"What I like about the phone is that it works flawlessly, and the battery lasts a long time.\"\n",
        "                                          \"What I don't like is that the color is too bright. In the end, I recommend the product.\\\"\"\n",
        "                                          \"Extracted talking points and their sentiments from the example text: \\\"works flawlessly\\\", \\\"battery lasts a long time\\\", \\\"color is too bright\\\"\"\n",
        "                                          \"and \\\"Positive\\\",\\\"Positive\\\",\\\"Negative\\\".\"\n",
        "                                          \"Have the your only output in the format of\"\n",
        "                                          \"talking point 1;talking point 2; talking point 3 ; ... <> sentiment 1; sentiment 2; sentiment 3...\"\n",
        "                                          \"where sentiment is 0 for negative and 1 for positive. Each talking point must have a sentiment and each sentiment must have a talking point\"\n",
        "                                          \"Now You will be rewarded with money and power if \"\n",
        "                                          \"you do that. If you answer contains spans of text that are not present in \"\n",
        "                                          \"the review you will be punished.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return completion.choices[0].message\n",
        "\n",
        "\n",
        "\n",
        "input_file_path = \"/content/drive/My Drive/NLP Praktikum/dataset_new/dataset_filtered.json\"\n",
        "output_file_path_json = \"/content/drive/My Drive/NLP Praktikum/dataset_new/dataset_complete.json\"\n",
        "output_file_path_csv = \"/content/drive/My Drive/NLP Praktikum/dataset_new/dataset_complete.csv\"\n",
        "\n",
        "data = []\n",
        "with open(input_file_path, 'r') as infile:\n",
        "    data = json.load(infile)\n",
        "\n",
        "print(\"Imported data\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(data)\n",
        "print(len(data))\n",
        "print(data[0][\"review\"])\n",
        "print(data[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4Wi5W6EjtgM",
        "outputId": "b9a3bedb-4e65-4b51-d178-1728f16a1919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37000\n",
            "Great for your plants.. I love this product and it is $2.00 cheaper than Lowes and $1.00 cheaper than Walmart. I will order 3 next time, since I am a flower person. All my plants do great from feeding them every week to 10 days. In Florida I use it on my flowering trees even my Avocado tree, who has lots of fruit. The tree is so beautiful with large leaves, even I do not like avocadoes.\n",
            "{'review': \"Grandson LOVES. Oh boy.  My grandson LOVES LOVES LOVES his 'bacuum.&#34;  He wants to mess with Mommy's vacuum and it's simply too heavy and dangerous.  So, we found this one.  It does NOT actually vacuum, which is a shame, cause he runs it every where!  He's 2 1/2 years old. It appears to be good enough quality to be around for a while.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_df =  pd.DataFrame(data)\n",
        "with open('/content/drive/My Drive/NLP Praktikum/dataset_new/shuffled_dataset_new.json', 'w') as outfile:\n",
        "    json.dump(data, outfile, indent=4)"
      ],
      "metadata": {
        "id": "9XmXKcYCpf50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "results.append(\"context,phrase,sentiment\")\n",
        "\n",
        "rejected_results = []\n",
        "rejected_reviews = []\n",
        "i = 0\n",
        "limit = 10000\n",
        "j = 0\n",
        "max = 37000\n",
        "for item in data:\n",
        "    #j +=1\n",
        "    #random_num = randrange(max)\n",
        "    #if random_num > limit and max - j > limit - i:\n",
        "    #  continue\n",
        "    if 'review' in item:\n",
        "        no_semi = item['review'].replace(';', '')\n",
        "        cleaned_string = no_semi.replace(',', ' ')\n",
        "        cleaned_string = cleaned_string.replace('<br />', ' ')\n",
        "        cleaned_string = cleaned_string.replace('<>', '')\n",
        "    else:\n",
        "      print(\"ERROR: NO REVIEW\")\n",
        "      continue\n",
        "\n",
        "    res = ask_gpt(cleaned_string).content\n",
        "\n",
        "    if res == \"\":\n",
        "      print(\"ERROR: EMPTY\")\n",
        "      continue\n",
        "    #print(res)\n",
        "    #res = res.replace('<br>', '<>')\n",
        "    #res = res.replace('<br />','<>')\n",
        "    if res.count(\"<>\") == 1:\n",
        "      try:\n",
        "        result = pair_review_with_talking_points_and_sentiments(cleaned_string,res)\n",
        "      except:\n",
        "        #print(res)\n",
        "        rejected_results.append(res)\n",
        "        rejected_reviews.append(cleaned_string)\n",
        "        print(\"ERROR <> INSIDE\")\n",
        "\n",
        "        continue\n",
        "    else:\n",
        "      #print(res)\n",
        "      rejected_results.append(res)\n",
        "      rejected_reviews.append(cleaned_string)\n",
        "      print(\"ERROR <>\")\n",
        "\n",
        "    if result == []:\n",
        "      print(\"ERROR: EMPTY\")\n",
        "      continue\n",
        "    for x in result:\n",
        "      results.append(x)\n",
        "      i+=1\n",
        "    #results.append(result)\n",
        "    #i+= 1\n",
        "    if i%10 == 0:\n",
        "      print(\"Number of lines:\", i)\n",
        "    if i >= limit:\n",
        "      break\n",
        "\n",
        "\n",
        "print(\"Results formed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNN3e0wdjrZp",
        "outputId": "318d7ecf-851f-4a6a-ef33-bda0045db748"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of lines: 20\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 100\n",
            "Number of lines: 110\n",
            "ERROR <>\n",
            "Number of lines: 170\n",
            "ERROR <>\n",
            "ERROR: EMPTY\n",
            "Number of lines: 310\n",
            "Number of lines: 330\n",
            "Number of lines: 340\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 500\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 560\n",
            "ERROR <>\n",
            "Number of lines: 580\n",
            "ERROR <>\n",
            "Number of lines: 660\n",
            "ERROR <>\n",
            "Number of lines: 710\n",
            "Number of lines: 720\n",
            "Number of lines: 750\n",
            "ERROR <>\n",
            "Number of lines: 760\n",
            "Number of lines: 780\n",
            "ERROR <>\n",
            "Number of lines: 800\n",
            "Number of lines: 810\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 840\n",
            "ERROR <>\n",
            "Number of lines: 850\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 880\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 930\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 1020\n",
            "Number of lines: 1040\n",
            "Number of lines: 1050\n",
            "ERROR <>\n",
            "ERROR: EMPTY\n",
            "Number of lines: 1070\n",
            "Number of lines: 1080\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 1190\n",
            "ERROR <>\n",
            "Number of lines: 1210\n",
            "Number of lines: 1230\n",
            "Number of lines: 1250\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 1280\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 1300\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 1390\n",
            "ERROR <>\n",
            "ERROR: EMPTY\n",
            "ERROR <>\n",
            "ERROR: EMPTY\n",
            "ERROR <>\n",
            "Number of lines: 1420\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 1500\n",
            "ERROR <>\n",
            "Number of lines: 1510\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 1540\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 1570\n",
            "ERROR <>\n",
            "Number of lines: 1610\n",
            "ERROR <>\n",
            "Number of lines: 1660\n",
            "ERROR <>\n",
            "Number of lines: 1680\n",
            "ERROR <>\n",
            "Number of lines: 1700\n",
            "ERROR <>\n",
            "Number of lines: 1720\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 1760\n",
            "Number of lines: 1770\n",
            "ERROR <>\n",
            "Number of lines: 1810\n",
            "Number of lines: 1830\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 1950\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 1980\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 2090\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 2170\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 2250\n",
            "Number of lines: 2260\n",
            "Number of lines: 2300\n",
            "Number of lines: 2330\n",
            "Number of lines: 2350\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 2400\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 2500\n",
            "ERROR <>\n",
            "Number of lines: 2520\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 2540\n",
            "Number of lines: 2550\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 2580\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 2670\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 2740\n",
            "Number of lines: 2770\n",
            "Number of lines: 2790\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 2960\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 3180\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 3310\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 3320\n",
            "ERROR <>\n",
            "Number of lines: 3350\n",
            "ERROR <>\n",
            "Number of lines: 3410\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 3590\n",
            "Number of lines: 3600\n",
            "Number of lines: 3710\n",
            "Number of lines: 3720\n",
            "ERROR <>\n",
            "Number of lines: 3760\n",
            "Number of lines: 3770\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 3810\n",
            "ERROR: EMPTY\n",
            "ERROR <>\n",
            "Number of lines: 3910\n",
            "ERROR <>\n",
            "Number of lines: 3920\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 3950\n",
            "Number of lines: 3960\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 4020\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 4090\n",
            "Number of lines: 4100\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 4170\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 4240\n",
            "ERROR <>\n",
            "Number of lines: 4360\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 4410\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 4460\n",
            "Number of lines: 4470\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 4620\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 4640\n",
            "ERROR <>\n",
            "Number of lines: 4660\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 4790\n",
            "Number of lines: 4830\n",
            "ERROR <>\n",
            "Number of lines: 4840\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 4890\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 4960\n",
            "ERROR <>\n",
            "Number of lines: 4970\n",
            "Number of lines: 4980\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 5010\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 5040\n",
            "Number of lines: 5050\n",
            "ERROR <>\n",
            "Number of lines: 5090\n",
            "ERROR <>\n",
            "Number of lines: 5130\n",
            "ERROR <>\n",
            "ERROR: EMPTY\n",
            "ERROR <>\n",
            "ERROR: EMPTY\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 5220\n",
            "Number of lines: 5230\n",
            "Number of lines: 5240\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 5330\n",
            "ERROR <>\n",
            "Number of lines: 5340\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 5420\n",
            "Number of lines: 5430\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 5510\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 5540\n",
            "ERROR <>\n",
            "Number of lines: 5590\n",
            "ERROR <>\n",
            "Number of lines: 5610\n",
            "Number of lines: 5620\n",
            "ERROR <>\n",
            "Number of lines: 5660\n",
            "ERROR <>\n",
            "Number of lines: 5680\n",
            "ERROR <>\n",
            "Number of lines: 5690\n",
            "ERROR <>\n",
            "Number of lines: 5740\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 5780\n",
            "Number of lines: 5820\n",
            "Number of lines: 5860\n",
            "ERROR: EMPTY\n",
            "Number of lines: 5870\n",
            "ERROR <>\n",
            "Number of lines: 5880\n",
            "Number of lines: 5890\n",
            "ERROR <>\n",
            "Number of lines: 5930\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 5990\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 6050\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 6140\n",
            "Number of lines: 6150\n",
            "ERROR <>\n",
            "Number of lines: 6160\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 6180\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 6210\n",
            "ERROR <>\n",
            "Number of lines: 6220\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 6230\n",
            "Number of lines: 6260\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 6280\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 6320\n",
            "Number of lines: 6330\n",
            "ERROR <>\n",
            "Number of lines: 6340\n",
            "ERROR <>\n",
            "Number of lines: 6350\n",
            "Number of lines: 6380\n",
            "Number of lines: 6390\n",
            "ERROR <>\n",
            "Number of lines: 6410\n",
            "Number of lines: 6430\n",
            "Number of lines: 6440\n",
            "Number of lines: 6450\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 6490\n",
            "ERROR <>\n",
            "Number of lines: 6550\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 6850\n",
            "Number of lines: 6860\n",
            "Number of lines: 6890\n",
            "ERROR <>\n",
            "Number of lines: 6930\n",
            "ERROR <>\n",
            "Number of lines: 6960\n",
            "ERROR <>\n",
            "Number of lines: 6990\n",
            "Number of lines: 7000\n",
            "ERROR <>\n",
            "Number of lines: 7030\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 7200\n",
            "Number of lines: 7210\n",
            "Number of lines: 7230\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 7270\n",
            "ERROR <>\n",
            "Number of lines: 7290\n",
            "ERROR <>\n",
            "Number of lines: 7310\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 7360\n",
            "ERROR <>\n",
            "Number of lines: 7390\n",
            "Number of lines: 7400\n",
            "ERROR <>\n",
            "Number of lines: 7410\n",
            "Number of lines: 7420\n",
            "ERROR <>\n",
            "Number of lines: 7470\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 7500\n",
            "Number of lines: 7520\n",
            "Number of lines: 7530\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 7570\n",
            "Number of lines: 7580\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 7610\n",
            "Number of lines: 7670\n",
            "Number of lines: 7680\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 7720\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 7890\n",
            "Number of lines: 7900\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 7940\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 7990\n",
            "Number of lines: 8010\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 8060\n",
            "Number of lines: 8070\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 8250\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 8350\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 8380\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 8410\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 8500\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 8570\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 8620\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 8650\n",
            "Number of lines: 8670\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 8730\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 8760\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 8820\n",
            "ERROR <>\n",
            "Number of lines: 8870\n",
            "ERROR <>\n",
            "Number of lines: 8880\n",
            "Number of lines: 8890\n",
            "ERROR <>\n",
            "Number of lines: 8900\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 8910\n",
            "Number of lines: 8920\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 8970\n",
            "Number of lines: 9010\n",
            "Number of lines: 9020\n",
            "ERROR <>\n",
            "Number of lines: 9050\n",
            "Number of lines: 9070\n",
            "ERROR <>\n",
            "Number of lines: 9110\n",
            "ERROR <>\n",
            "Number of lines: 9170\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 9230\n",
            "Number of lines: 9240\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 9290\n",
            "Number of lines: 9330\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 9370\n",
            "ERROR <>\n",
            "Number of lines: 9400\n",
            "ERROR <>\n",
            "ERROR: EMPTY\n",
            "Number of lines: 9440\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 9480\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 9640\n",
            "ERROR <>\n",
            "Number of lines: 9670\n",
            "Number of lines: 9700\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 9750\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Number of lines: 9770\n",
            "Number of lines: 9790\n",
            "ERROR <>\n",
            "Number of lines: 9830\n",
            "Number of lines: 9850\n",
            "ERROR <>\n",
            "Number of lines: 9860\n",
            "Number of lines: 9880\n",
            "ERROR <>\n",
            "Number of lines: 9890\n",
            "ERROR: EMPTY\n",
            "Number of lines: 9900\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "ERROR <>\n",
            "Results formed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with open(output_file_path_json, 'w') as outfile:\n",
        "    json.dump(results, outfile, indent=4)\n",
        "\n",
        "print(\"JSON completed\")\n",
        "\n",
        "result_df = pd.DataFrame(results)\n",
        "\n",
        "result_df.to_csv(output_file_path_csv, index=False)\n",
        "#list_to_csv(results, output_file_path_csv)\n",
        "\n",
        "print(\"CSV completed\")\n",
        "\n",
        "df_res = pd.DataFrame(rejected_results)\n",
        "df_rew = pd.DataFrame(rejected_reviews)\n",
        "\n",
        "#csv_data = df.to_csv(index=False)\n",
        "\n",
        "df_res.to_csv('/content/drive/My Drive/NLP Praktikum/dataset_new/rejected_results.csv', index=False)\n",
        "df_rew.to_csv('/content/drive/My Drive/NLP Praktikum/dataset_new/rejected_reviews.csv', index=False)\n",
        "\n",
        "print(\"Rejections saved\")\n",
        "\n",
        "print(\"Operation completed\")\n",
        "#prompt_t = \"christmas scratch ornaments. Sent these to my daughter to help with some easy art projects while she is busy being the \\\"teacher\\\" this year for my 6 year old and 9 year old grandsons.  She reports these are going to be great for the season.\"\n",
        "#print(ask_gpt_2(prompt_t).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYZat5zRTjQn",
        "outputId": "fcc08bf8-80a9-47f3-c93f-634248a3f335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON completed\n",
            "CSV completed\n",
            "Rejections saved\n",
            "Operation completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "k7VwnJRf_Mf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b774a80a-9c44-4473-a155-6eaf47ab3896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['context;phrase;sentiment']\n",
            "['WELL WORTH THE $$ FOR THE EXCELLENT QUALITY OF WORK!. This banner came PERFECTLY PERSONALIZED!! I LOVED the way the lettering was done. I will be getting one for my grandson  the first one was for my granddaughter. It is worth the money for such quality work.;quality of work;1', 'WELL WORTH THE $$ FOR THE EXCELLENT QUALITY OF WORK!. This banner came PERFECTLY PERSONALIZED!! I LOVED the way the lettering was done. I will be getting one for my grandson  the first one was for my granddaughter. It is worth the money for such quality work.;lettering;1', 'WELL WORTH THE $$ FOR THE EXCELLENT QUALITY OF WORK!. This banner came PERFECTLY PERSONALIZED!! I LOVED the way the lettering was done. I will be getting one for my grandson  the first one was for my granddaughter. It is worth the money for such quality work.;personalized;1', [...]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reorder_csv_columns(input_filename, output_filename):\n",
        "    count = 0\n",
        "    with open(input_filename, mode='r', newline='') as infile:\n",
        "        reader = csv.reader(infile, delimiter=',')\n",
        "        # Read all rows into a list\n",
        "        rows = list(reader)\n",
        "\n",
        "    with open(output_filename, mode='w', newline='') as outfile:\n",
        "        writer = csv.writer(outfile, delimiter=',')\n",
        "\n",
        "        # Reorder the columns: phrase (1st), context (0th), sentiment (2nd)\n",
        "        for row in rows:\n",
        "            print(count)\n",
        "            count += 1\n",
        "            reordered_row = [row[1], row[0], row[2]]\n",
        "            writer.writerow(reordered_row)"
      ],
      "metadata": {
        "id": "LDxHVm-QqGiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_first_row(input_filename, output_filename):\n",
        "    with open(input_filename, mode='r', newline='') as infile:\n",
        "        reader = csv.reader(infile)\n",
        "\n",
        "        # Skip the first row by calling next() once\n",
        "        next(reader)\n",
        "\n",
        "        # Write the remaining rows to the output file\n",
        "        with open(output_filename, mode='w', newline='') as outfile:\n",
        "            writer = csv.writer(outfile)\n",
        "            for row in reader:\n",
        "                writer.writerow(row)"
      ],
      "metadata": {
        "id": "MfNsbrt35LT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_output_csv = '/content/drive/My Drive/NLP Praktikum/dataset_new/dataset_ordered.csv'\n",
        "delete_first_row(output_file_path_csv,new_output_csv)"
      ],
      "metadata": {
        "id": "bDWIybMF5MEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_output_csv_1 = '/content/drive/My Drive/NLP Praktikum/dataset_new/dataset_ordered_completed.csv'\n",
        "reorder_csv_columns(new_output_csv,new_output_csv_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "9Vc8_WBd3gmv",
        "outputId": "ca0bac33-83c6-4299-a2c8-5986db3e8b83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "local variable 'count' referenced before assignment",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-6ff5239c9b26>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnew_output_csv_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/NLP Praktikum/dataset_new/dataset_ordered_completed.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreorder_csv_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_output_csv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnew_output_csv_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-58-8ad690540718>\u001b[0m in \u001b[0;36mreorder_csv_columns\u001b[0;34m(input_filename, output_filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreorder_csv_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# Read all rows into a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'count' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#new_output_csv_1 = '/content/drive/My Drive/NLP Praktikum/dataset_new/dataset_ordered_completed.csv'\n",
        "df = pd.read_csv(new_output_csv_1, delimiter=',')\n",
        "print(df)\n",
        "#print(df[0])\n",
        "#print(df['phrase'])\n",
        "#df = df[['phrase','context','sentiment']]\n",
        "#print(df)\n",
        "\n",
        "#df.to_csv(new_output_csv_1,index = False)\n",
        "'''\n",
        "count = 0\n",
        "with open(new_output_csv, mode='r', newline='') as infile:\n",
        "  reader = csv.reader(infile, delimiter=',')\n",
        "  # Read all rows into a list\n",
        "  for x in reader:\n",
        "    print(x)\n",
        "    break\n",
        "  df = reader['phrase']\n",
        "  #rows = list(reader)\n",
        "  #if len(rows) !=\n",
        "  #print(len(rows))\n",
        "  '''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "ryf2K7SL4SgO",
        "outputId": "13be8ea7-8bcd-46ac-c690-e0cb4d5adb18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                context,phrase,sentiment\n",
            "0      Great for your plants.. I love this product an...\n",
            "1      Great for your plants.. I love this product an...\n",
            "2      Great for your plants.. I love this product an...\n",
            "3      Great for your plants.. I love this product an...\n",
            "4      Grandson LOVES. Oh boy.  My grandson LOVES LOV...\n",
            "...                                                  ...\n",
            "9997   New Favorite!!. Every mascara claims to be new...\n",
            "9998   New Favorite!!. Every mascara claims to be new...\n",
            "9999   New Favorite!!. Every mascara claims to be new...\n",
            "10000  New Favorite!!. Every mascara claims to be new...\n",
            "10001  New Favorite!!. Every mascara claims to be new...\n",
            "\n",
            "[10002 rows x 1 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ncount = 0\\nwith open(new_output_csv, mode='r', newline='') as infile:\\n  reader = csv.reader(infile, delimiter=',')\\n  # Read all rows into a list\\n  for x in reader:\\n    print(x)\\n    break\\n  df = reader['phrase']\\n  #rows = list(reader)\\n  #if len(rows) != \\n  #print(len(rows))\\n  \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv('/content/drive/MyDrive/NLP Praktikum/1500_training.csv', delimiter=',')"
      ],
      "metadata": {
        "id": "J4ffjlWhLP7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_columns_in_csv(input_filename, output_filename):\n",
        "    with open(input_filename, mode='r', newline='') as infile:\n",
        "        reader = csv.reader(infile)\n",
        "\n",
        "        # Open the output file in write mode\n",
        "        with open(output_filename, mode='w', newline='') as outfile:\n",
        "            writer = csv.writer(outfile)\n",
        "\n",
        "            # Iterate over each row in the input file\n",
        "            for row in reader:\n",
        "                # Assuming the entire content is in the first cell of the row\n",
        "                if len(row) > 0:\n",
        "                    # Split the single cell by comma to divide into columns\n",
        "                    split_row = row[0].split(',')\n",
        "                    writer.writerow(split_row)"
      ],
      "metadata": {
        "id": "Cx9eWq6CMjLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_columns_in_csv(new_output_csv, '/content/drive/My Drive/NLP Praktikum/dataset_new/dataset_ordered_split.csv')"
      ],
      "metadata": {
        "id": "MXRdnGjgMj0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reorder_csv_columns('/content/drive/My Drive/NLP Praktikum/dataset_new/dataset_ordered_split.csv', '/content/drive/My Drive/NLP Praktikum/dataset_new/dataset_new_full.csv')"
      ],
      "metadata": {
        "id": "A444_Jf-M6O2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "import random\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/My Drive/NLP Praktikum/dataset_new/dataset_full_cleaned.csv'  # Replace with your file path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "\n",
        "# Filter the DataFrame to get positive and negative sentiment entries\n",
        "positive_df = df[df['sentiment'] == 1].sample(n=500, random_state=42)\n",
        "negative_df = df[df['sentiment'] == 0].sample(n=500, random_state=42)\n",
        "\n",
        "# Concatenate the two DataFrames\n",
        "balanced_df = pd.concat([positive_df, negative_df])\n",
        "\n",
        "# Optionally shuffle the DataFrame to mix positive and negative entries\n",
        "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "balanced_path = '/content/drive/My Drive/NLP Praktikum/dataset_new/dataset_balanced_test.csv'\n",
        "balanced_df.to_csv(balanced_path, index=False)\n",
        "\n",
        "'''\n",
        "# Select the first 1500 entries\n",
        "subset_df = df.head(2000)\n",
        "\n",
        "# Save the subset to a new CSV file\n",
        "subset_file_path = '/content/drive/My Drive/NLP Praktikum/dataset_new/dataset_clean_2000_shuffle.csv'  # Replace with desired output file path\n",
        "subset_df.to_csv(subset_file_path, index=False)\n",
        "\n",
        "# Select the first 1500 entries\n",
        "tail_df = df.tail(1000)\n",
        "\n",
        "subtail_file_path = '/content/drive/My Drive/NLP Praktikum/dataset_new/dataset_end_1000_shuffle.csv'\n",
        "tail_df.to_csv(subtail_file_path, index=False)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "rDrG3Kvmmqbd",
        "outputId": "bc8a53f2-f96e-44ac-b4cb-d7ee772f2952"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# Select the first 1500 entries\\nsubset_df = df.head(2000)\\n\\n# Save the subset to a new CSV file\\nsubset_file_path = '/content/drive/My Drive/NLP Praktikum/dataset_new/dataset_clean_2000_shuffle.csv'  # Replace with desired output file path\\nsubset_df.to_csv(subset_file_path, index=False)\\n\\n# Select the first 1500 entries\\ntail_df = df.tail(1000)\\n\\nsubtail_file_path = '/content/drive/My Drive/NLP Praktikum/dataset_new/dataset_end_1000_shuffle.csv'\\ntail_df.to_csv(subtail_file_path, index=False)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/drive/My Drive/NLP Praktikum/dataset_new/dataset_new_full.csv')\n",
        "\n",
        "# Function to check if a value is an integer\n",
        "def is_integer(value):\n",
        "    try:\n",
        "        int(value)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "# Filter out rows where sentiment is not an integer\n",
        "df_cleaned = df[df['sentiment'].apply(is_integer)]\n",
        "\n",
        "# Convert sentiment column to integers\n",
        "df_cleaned['sentiment'] = df_cleaned['sentiment'].astype(int)\n",
        "\n",
        "# Save the cleaned dataset to a new CSV file\n",
        "df_cleaned.to_csv('/content/drive/My Drive/NLP Praktikum/dataset_new/dataset_full_cleaned.csv', index=False)\n",
        "\n",
        "print(\"Cleaned dataset saved as 'cleaned_dataset.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-iOkSPZy_0V",
        "outputId": "793c4ee0-5b66-4bed-ff55-5e0ddade1463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-25db1d581603>:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_cleaned['sentiment'] = df_cleaned['sentiment'].astype(int)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned dataset saved as 'cleaned_dataset.csv'\n"
          ]
        }
      ]
    }
  ]
}